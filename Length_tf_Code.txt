from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords

stop=set(stopwords.words('english'))
stri=""

with open("idf_final.txt") as f:
    data=f.readlines()
    for x in data:
        stri+=x;
    idf=word_tokenize(stri)
stri=""
import os
  
# Folder Path
path = r"path of the folder where the code is executed"
  
# Change the directory
os.chdir(path)

key =list()
# iterate through all file
for file in os.listdir():
    # Check whether file is in text format or not
    if file.endswith(".txt"):
        file_path = f"{path}\{file}"
        with open(file_path) as f:
            data =f.readlines()
            for x in data:
                val=x.strip()
                stri=stri+val
            tok=word_tokenize(stri)
            ans=list()
            for i in range(0,len(tok)):
                if tok[i].lower() in stop:
                    pass
                else:
                    ans.append(tok[i])
            none=""
            ans = list(map(lambda x: x.replace('\n',none).replace('\\n',none).replace(',',none),ans))
            for i in range(len(ans)-1):
                ans[i]=ans[i].lower()
                if ans[i]=='' or ans[i]=='.' or ans[i].isalpha() == False:
                    pass
                else:
                    key.append(ans[i])
            ans.clear()
            stri=""

key_final=list()

for i in key:
    if i in key_final:
        pass
    else:
        key_final.append(i)

key_final.sort()

key.clear()
z=0
tf=list()
tf_fin = list()
len_fin = list()
for file in os.listdir():
    # Check whether file is in text format or not
    if file.endswith(".txt"):
        file_path = f"{path}\{file}"
        with open(file_path) as f:
            data =f.readlines()
            for x in data:
                val=x.strip()
                stri=stri+val
            tok=word_tokenize(stri)
            ans=list()
            for i in range(0,len(tok)):
                if tok[i].lower() in stop:
                    pass
                else:
                    ans.append(tok[i])
            none=""
            ans = list(map(lambda x: x.replace('\n',none).replace('\\n',none).replace(',',none),ans))
            for i in range(len(ans)-1):
                ans[i]=ans[i].lower()
                if ans[i]=='' or ans[i]=='.' or ans[i].isalpha() == False:
                    pass
                else:
                    key.append(ans[i])
            
            for i in range(len(key_final)):
                st=""
                st=key_final[i]
                x=key.count(st)
                
                if x != 0:
                    tf_fin.append(str(z+1)+" "+str(i+1)+" "+str(x))
            
            len_fin.append(len(key))
            z+=1
            ans.clear()
            key.clear()
            stri=""




with open("length_final.txt","a+") as f:
    for x in len_fin:
        f.write("%s\n" % x)